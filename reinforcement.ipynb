{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMr/g+cXqKth11tWljD2g6d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A41447/ADM-2303A51447/blob/main/reinforcement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vjOCU3X4RlJN"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "\n",
        "class SimpleDroneEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    A simple 2D drone environment for RL navigation.\n",
        "    Drone must reach a goal while avoiding obstacles.\n",
        "    \"\"\"\n",
        "    def __init__(self, grid_size=10):\n",
        "        super(SimpleDroneEnv, self).__init__()\n",
        "        self.grid_size = grid_size\n",
        "        self.max_steps = 200\n",
        "\n",
        "        # Observation: [x, y, goal_x, goal_y]\n",
        "        self.observation_space = spaces.Box(low=0, high=grid_size, shape=(4,), dtype=np.float32)\n",
        "\n",
        "        # Actions: 0=up, 1=down, 2=left, 3=right\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "\n",
        "        self.obstacles = self._generate_obstacles()\n",
        "        self.reset()\n",
        "\n",
        "    def _generate_obstacles(self):\n",
        "        # Random obstacles (except borders)\n",
        "        obstacles = set()\n",
        "        for _ in range(10):\n",
        "            ox, oy = np.random.randint(1, self.grid_size-1, size=2)\n",
        "            obstacles.add((ox, oy))\n",
        "        return obstacles\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.steps = 0\n",
        "        self.agent_pos = np.array([1, 1])\n",
        "        self.goal_pos = np.array([self.grid_size-2, self.grid_size-2])\n",
        "        obs = np.concatenate((self.agent_pos, self.goal_pos)).astype(np.float32)\n",
        "        return obs, {}\n",
        "\n",
        "    def step(self, action):\n",
        "        self.steps += 1\n",
        "        x, y = self.agent_pos\n",
        "\n",
        "        if action == 0:   # up\n",
        "            y += 1\n",
        "        elif action == 1: # down\n",
        "            y -= 1\n",
        "        elif action == 2: # left\n",
        "            x -= 1\n",
        "        elif action == 3: # right\n",
        "            x += 1\n",
        "\n",
        "        # Stay within bounds\n",
        "        x = np.clip(x, 0, self.grid_size-1)\n",
        "        y = np.clip(y, 0, self.grid_size-1)\n",
        "        new_pos = (x, y)\n",
        "\n",
        "        reward = -0.1  # small step penalty\n",
        "        done = False\n",
        "\n",
        "        if new_pos in self.obstacles:\n",
        "            reward = -10.0\n",
        "            done = True\n",
        "        elif np.array_equal(new_pos, self.goal_pos):\n",
        "            reward = 20.0\n",
        "            done = True\n",
        "\n",
        "        self.agent_pos = np.array(new_pos)\n",
        "        obs = np.concatenate((self.agent_pos, self.goal_pos)).astype(np.float32)\n",
        "\n",
        "        if self.steps >= self.max_steps:\n",
        "            done = True\n",
        "\n",
        "        return obs, reward, done, False, {}\n",
        "\n",
        "    def render(self):\n",
        "        grid = np.full((self.grid_size, self.grid_size), ' ')\n",
        "        for (ox, oy) in self.obstacles:\n",
        "            grid[self.grid_size-oy-1, ox] = 'X'\n",
        "        grid[self.grid_size-self.agent_pos[1]-1, self.agent_pos[0]] = 'D'\n",
        "        grid[self.grid_size-self.goal_pos[1]-1, self.goal_pos[0]] = 'G'\n",
        "        print(\"\\n\".join(\"\".join(row) for row in grid))\n",
        "        print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "!pip install stable-baselines3\n",
        "from stable_baselines3 import PPO\n",
        "from __main__ import SimpleDroneEnv\n",
        "\n",
        "# Create environment\n",
        "env = SimpleDroneEnv(grid_size=10)\n",
        "\n",
        "# Train PPO agent\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "model.learn(total_timesteps=50_000)\n",
        "\n",
        "# Save model\n",
        "model.save(\"ppo_drone_simple\")\n",
        "\n",
        "# Evaluate\n",
        "obs, _ = env.reset()\n",
        "total_reward = 0\n",
        "for _ in range(200):\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, reward, done, _, _ = env.step(action)\n",
        "    total_reward += reward\n",
        "    env.render()\n",
        "    if done:\n",
        "        break\n",
        "\n",
        "print(f\"âœ… Test complete. Total reward: {total_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJhaOWjCSI_F",
        "outputId": "96fad30c-7115-4910-a748-969dd06d0fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (1.2.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.8.0+cu126)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.3)\n",
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 27.3     |\n",
            "|    ep_rew_mean     | -12.6    |\n",
            "| time/              |          |\n",
            "|    fps             | 1198     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 37.3        |\n",
            "|    ep_rew_mean          | -13.6       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 845         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019479834 |\n",
            "|    clip_fraction        | 0.333       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.37       |\n",
            "|    explained_variance   | 0.0453      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.72        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0368     |\n",
            "|    value_loss           | 8.62        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 51.7        |\n",
            "|    ep_rew_mean          | -14.6       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 688         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 8           |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019385148 |\n",
            "|    clip_fraction        | 0.317       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.32       |\n",
            "|    explained_variance   | 0.175       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.1         |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0384     |\n",
            "|    value_loss           | 2.09        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 67.6        |\n",
            "|    ep_rew_mean          | -15.4       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 685         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 11          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009141146 |\n",
            "|    clip_fraction        | 0.171       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.27       |\n",
            "|    explained_variance   | 0.0151      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.4         |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0163     |\n",
            "|    value_loss           | 1.56        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 87.5        |\n",
            "|    ep_rew_mean          | -16.3       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 681         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 15          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012886664 |\n",
            "|    clip_fraction        | 0.187       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.2        |\n",
            "|    explained_variance   | 0.0258      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.54        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0112     |\n",
            "|    value_loss           | 1.78        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 104         |\n",
            "|    ep_rew_mean          | -17         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 682         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 18          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012281977 |\n",
            "|    clip_fraction        | 0.0713      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.16       |\n",
            "|    explained_variance   | 0.0104      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.387       |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.00326    |\n",
            "|    value_loss           | 2.04        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 121         |\n",
            "|    ep_rew_mean          | -17.7       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 652         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 21          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016831292 |\n",
            "|    clip_fraction        | 0.169       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.08       |\n",
            "|    explained_variance   | 0.000332    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.771       |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0108     |\n",
            "|    value_loss           | 1.88        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 136         |\n",
            "|    ep_rew_mean          | -18.2       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 652         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 25          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011111354 |\n",
            "|    clip_fraction        | 0.0508      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.14       |\n",
            "|    explained_variance   | -0.00403    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.421       |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00271    |\n",
            "|    value_loss           | 1.86        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 152          |\n",
            "|    ep_rew_mean          | -18.7        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 652          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 28           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064268173 |\n",
            "|    clip_fraction        | 0.0669       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.18        |\n",
            "|    explained_variance   | 0.00287      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.575        |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00349     |\n",
            "|    value_loss           | 1.79         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 166         |\n",
            "|    ep_rew_mean          | -19.2       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 653         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 31          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004248726 |\n",
            "|    clip_fraction        | 0.046       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.2        |\n",
            "|    explained_variance   | 0.001       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.03        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00182    |\n",
            "|    value_loss           | 1.79        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 179         |\n",
            "|    ep_rew_mean          | -19.5       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 638         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 35          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005636641 |\n",
            "|    clip_fraction        | 0.0189      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.19       |\n",
            "|    explained_variance   | -0.0116     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.875       |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00167    |\n",
            "|    value_loss           | 1.85        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 188         |\n",
            "|    ep_rew_mean          | -19.7       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 640         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 38          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009124083 |\n",
            "|    clip_fraction        | 0.0758      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.2        |\n",
            "|    explained_variance   | 0.00091     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1           |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0035     |\n",
            "|    value_loss           | 1.78        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 193         |\n",
            "|    ep_rew_mean          | -19.8       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 643         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009107256 |\n",
            "|    clip_fraction        | 0.0386      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.19       |\n",
            "|    explained_variance   | 0.000724    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.776       |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00225    |\n",
            "|    value_loss           | 1.87        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 196          |\n",
            "|    ep_rew_mean          | -19.9        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 642          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 44           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062176157 |\n",
            "|    clip_fraction        | 0.0573       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.21        |\n",
            "|    explained_variance   | 0.000603     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1            |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.00281     |\n",
            "|    value_loss           | 1.96         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 196          |\n",
            "|    ep_rew_mean          | -19.9        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 630          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 48           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038070572 |\n",
            "|    clip_fraction        | 0.0307       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.2         |\n",
            "|    explained_variance   | 0.00147      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.576        |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.0011      |\n",
            "|    value_loss           | 1.79         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 197         |\n",
            "|    ep_rew_mean          | -19.9       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 632         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 51          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011843574 |\n",
            "|    clip_fraction        | 0.0661      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.16       |\n",
            "|    explained_variance   | -0.00112    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.83        |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0029     |\n",
            "|    value_loss           | 1.78        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 197          |\n",
            "|    ep_rew_mean          | -19.9        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 633          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 54           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039606765 |\n",
            "|    clip_fraction        | 0.0379       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.14        |\n",
            "|    explained_variance   | -0.00245     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.18         |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.00265     |\n",
            "|    value_loss           | 1.8          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 197          |\n",
            "|    ep_rew_mean          | -19.9        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 632          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 58           |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0132804625 |\n",
            "|    clip_fraction        | 0.141        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.22        |\n",
            "|    explained_variance   | -0.00082     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.558        |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.00937     |\n",
            "|    value_loss           | 1.94         |\n",
            "------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}